{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WYq1Yz06breD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTc5ERo3FGRN"
      },
      "source": [
        "## Reading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "puKPHtnH0pIG"
      },
      "outputs": [],
      "source": [
        "s1 = pd.read_csv(\"../s1.csv\")\n",
        "# df2001 = pd.read_csv(\"../df2001.csv\")\n",
        "# df2003 = pd.read_csv(\"../df2003.csv\")\n",
        "# df2005 = pd.read_csv(\"../df2005.csv\")\n",
        "# df2007 = pd.read_csv(\"../df2007.csv\")\n",
        "# df2009 = pd.read_csv(\"../df2009.csv\")\n",
        "# df2011 = pd.read_csv(\"../df2011.csv\")\n",
        "# df2013 = pd.read_csv(\"../df2013.csv\")\n",
        "# df2015 = pd.read_csv(\"../df2015.csv\")\n",
        "# df2017 = pd.read_csv(\"../df2017.csv\")\n",
        "# df2019 = pd.read_csv(\"../df2019.csv\")\n",
        "# df2021 = pd.read_csv(\"../df2021.csv\")\n",
        "df2020 = pd.read_csv(\"../df2020.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZd_8wpNFIYx"
      },
      "source": [
        "## Droping cols and OneHotEncoding aka set dummy variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3jO-8xydbpbp"
      },
      "outputs": [],
      "source": [
        "def preprocess(csv_file):\n",
        "  csv_file = csv_file.drop(['lease_commence_date'], axis = 1)\n",
        "  csv_file = csv_file.drop(['Unnamed: 0'],axis = 1)\n",
        "  csv_file = csv_file.drop(['address'],axis = 1)\n",
        "\n",
        "  onehot = OneHotEncoder()\n",
        "\n",
        "  town_df = pd.DataFrame(onehot.fit_transform(csv_file[['town']]).toarray())\n",
        "  town_df.columns = onehot.get_feature_names_out(['town'])\n",
        "\n",
        "  flat_model_df = pd.DataFrame(onehot.fit_transform(csv_file[['flat_model']]).toarray())\n",
        "  flat_model_df.columns = onehot.get_feature_names_out(['flat_model'])\n",
        "\n",
        "  flat_type_df = pd.DataFrame(onehot.fit_transform(csv_file[['flat_type']]).toarray())\n",
        "  flat_type_df.columns = onehot.get_feature_names_out(['flat_type'])\n",
        "\n",
        "  csv_file = csv_file.join([town_df, flat_model_df, flat_type_df])\n",
        "  csv_file = csv_file.drop(['town','flat_type','flat_model'], axis = 1)\n",
        "\n",
        "  return csv_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mfVnM0fIOIUf"
      },
      "outputs": [],
      "source": [
        "s1     = preprocess(s1)\n",
        "# df2001 = preprocess(df2001)\n",
        "# df2003 = preprocess(df2003)\n",
        "# df2005 = preprocess(df2005)\n",
        "# df2007 = preprocess(df2007)\n",
        "# df2009 = preprocess(df2009)\n",
        "# df2011 = preprocess(df2011)\n",
        "# df2013 = preprocess(df2013)\n",
        "# df2015 = preprocess(df2015)\n",
        "# df2017 = preprocess(df2017)\n",
        "# df2019 = preprocess(df2019)\n",
        "# df2021 = preprocess(df2021)\n",
        "df2020 = preprocess(df2020)\n",
        "\n",
        "savefile = open(\"savefile.txt\", \"w\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejj4tNAdFZ6y"
      },
      "source": [
        "## Spliting data to training and validation set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test set S1.1\n",
        "s1 = s1.loc[s1['k_fold'] == 1]\n",
        "s1 = s1.drop(['k_fold'],axis = 1)\n",
        "\n",
        "# \"Classes\" / actual values\n",
        "y_test = s1['resale_price'].tolist()\n",
        "\n",
        "# Values to test on\n",
        "s1  = s1.drop(['resale_price'], axis=1)\n",
        "x_test = s1.to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f20M4R0bVUsj"
      },
      "outputs": [],
      "source": [
        "def k_fold(dataset, k: int) -> list:\n",
        "  SSE_valid_acc = 0\n",
        "  SSE_test_acc = 0\n",
        "  for fold_num in range(1, k + 1):\n",
        "    print(f'Fold number {fold_num}...')\n",
        "    # Validation set\n",
        "    validation    = dataset.loc[dataset['k_fold'] == fold_num]\n",
        "    validation    = validation.drop(['k_fold'], axis = 1)\n",
        "    y_validation  = validation['resale_price'].tolist()\n",
        "    validation    = validation.drop(['resale_price'], axis = 1)\n",
        "    x_validation  = validation.to_numpy()\n",
        "\n",
        "    # Training set\n",
        "    train   = dataset.loc[dataset['k_fold'] != fold_num]\n",
        "    train   = train.drop(['k_fold'], axis = 1)\n",
        "    y_train = train['resale_price'].tolist()\n",
        "    train   = train.drop(['resale_price'], axis = 1)\n",
        "    x_train = train.to_numpy()\n",
        "\n",
        "    # =========== modeling ==========\n",
        "    \n",
        "    # Support Vector Regression\n",
        "    model = svm.SVR()\n",
        "\n",
        "    # Random Forest\n",
        "    #model = RandomForestRegressor(n_estimators = 110, max_depth = 14, random_state = 0)\n",
        "    model = model.fit(x_train, y_train)\n",
        "    y_validation_pred = model.predict(x_validation)\n",
        "\n",
        "    SSE_valid = sum((y_validation - y_validation_pred)**2)\n",
        "    SSE_valid_acc += SSE_valid\n",
        "\n",
        "    y_test_pred = model.predict(x_test)\n",
        "\n",
        "    SSE_test = sum((y_test - y_test_pred)**2)\n",
        "    SSE_test_acc += SSE_test\n",
        "    \n",
        "  SSE_valid_avg = SSE_valid_acc / k\n",
        "  SSE_test_avg = SSE_test_acc / k\n",
        "\n",
        "  savefile.write(f'K-fold Cross validation. Selected K = {k}\\n')\n",
        "  savefile.write(f'Average validation SSE = {SSE_valid_avg}\\n')\n",
        "  savefile.write(f'Average testing SSE = {SSE_test_avg}\\n')\n",
        "  savefile.flush()\n",
        "\n",
        "  print(f'K-fold Cross Validation. Selected K = {k}')\n",
        "  print(f'Average validation Sum of Squared Errors = {SSE_valid_avg}')\n",
        "  print(f'Average testing Sum of Squared Errors = {SSE_test_avg}')\n",
        "\n",
        "  return [SSE_valid_avg, SSE_test_avg]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def k_fold2(dataset) -> list:\n",
        "  print(\"Training...\")\n",
        "  # Validation set\n",
        "  validation    = dataset.loc[dataset['k_fold'] == 1]\n",
        "  validation    = validation.drop(['k_fold'], axis = 1)\n",
        "  y_validation  = validation['resale_price'].tolist()\n",
        "  validation    = validation.drop(['resale_price'], axis = 1)\n",
        "  x_validation  = validation.to_numpy()\n",
        "\n",
        "  # Training set\n",
        "  train   = dataset.loc[dataset['k_fold'] != 1]\n",
        "  train   = train.drop(['k_fold'], axis = 1)\n",
        "  y_train = train['resale_price'].tolist()\n",
        "  train   = train.drop(['resale_price'], axis = 1)\n",
        "  x_train = train.to_numpy()\n",
        "\n",
        "  # =========== modeling ==========\n",
        "  \n",
        "  # Support Vector Regression\n",
        "  model = svm.SVR()\n",
        "\n",
        "  model = model.fit(x_train, y_train)\n",
        "  y_validation_pred = model.predict(x_validation)\n",
        "\n",
        "  SSE_valid = sum((y_validation - y_validation_pred)**2)\n",
        "\n",
        "  y_test_pred = model.predict(x_test)\n",
        "\n",
        "  SSE_test = sum((y_test - y_test_pred)**2)\n",
        "  \n",
        "  print(f'Average validation Sum of Squared Errors = {SSE_valid}')\n",
        "  print(f'Average testing Sum of Squared Errors = {SSE_test}')\n",
        "\n",
        "  return [SSE_valid, SSE_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "id": "18NueEEhWpjm",
        "outputId": "86078b55-8881-48dc-94d9-2207563bcca7"
      },
      "outputs": [],
      "source": [
        "avg_results = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "year_range = {0 : \"2001\",\n",
        "              1 : \"2003\",\n",
        "              2 : \"2005\",\n",
        "              3 : \"2007\",\n",
        "              4 : \"2009\",\n",
        "              5 : \"2011\",\n",
        "              6 : \"2013\",\n",
        "              7 : \"2015\",\n",
        "              8 : \"2017\",\n",
        "              9 : \"2019\",\n",
        "              10: \"2021\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold number 1...\n",
            "Fold number 2...\n",
            "Fold number 3...\n",
            "Fold number 4...\n",
            "Fold number 5...\n",
            "Fold number 6...\n",
            "Fold number 7...\n",
            "Fold number 8...\n",
            "Fold number 9...\n",
            "Fold number 10...\n",
            "K-fold Cross Validation. Selected K = 10\n",
            "Average validation Sum of Squared Errors = 52683558166932.65\n",
            "Average testing Sum of Squared Errors = 34236858039764.113\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[52683558166932.65, 34236858039764.113]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# avg_results[0]= k_fold(df2001, 1)\n",
        "# validation sse = 508794190916643.0\n",
        "# test sse = 73370395116532.02\n",
        "# k_fold2(df2003)\n",
        "# k_fold2(df2005)\n",
        "# avg_results[1]= k_fold(df2003)\n",
        "# avg_results[2]= k_fold(df2005)\n",
        "# avg_results[3]= k_fold(df2007, 1)\n",
        "# avg_results[4]= k_fold(df2009, 1)\n",
        "# avg_results[5]= k_fold(df2011, 1)\n",
        "# avg_results[6]= k_fold(df2013, 1)\n",
        "# avg_results[7]= k_fold(df2015, 1)\n",
        "# avg_results[8]= k_fold(df2017, 1)\n",
        "# avg_results[9]= k_fold(df2019, 1)\n",
        "k_fold(df2020, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "add_flat = np.zeros(11553)\n",
        "df2021[\"flat_model_Premium Maisonette\"] = add_flat\n",
        "avg_results[10]= k_fold(df2021, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finding smallest error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lowest error\n",
        "# [validation, test]\n",
        "min_error = [-1, -1]\n",
        "\n",
        "# Which range gives the lowest error\n",
        "# [validation, test]\n",
        "min_error_index = [-1, -1]\n",
        "\n",
        "\n",
        "for col in range(2):\n",
        "    for result in range(11):\n",
        "        if (min_error[col] == -1):\n",
        "            min_error[col] = avg_results[result][col]\n",
        "            min_error_index[col] = result\n",
        "            continue\n",
        "        curr_error = min_error[col]\n",
        "        seen_error = avg_results[result][col]\n",
        "        if (curr_error > seen_error): # if smaller\n",
        "            min_error[col] = seen_error\n",
        "            min_error_index[col] = result\n",
        "\n",
        "print(f'Best starting year for validation: {year_range[min_error_index[0]]}')\n",
        "print(f'Best starting year for testing: {year_range[min_error_index[1]]}')\n",
        "\n",
        "savefile.write(\"Finished!\\n\")\n",
        "savefile.write(f'Best starting year for validation: {year_range[min_error_index[0]]}\\n')\n",
        "savefile.write(f'Best starting year for testing: {year_range[min_error_index[1]]}\\n')\n",
        "savefile.flush()\n",
        "savefile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(avg_results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of hdb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
