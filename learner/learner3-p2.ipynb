{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WYq1Yz06breD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTc5ERo3FGRN"
      },
      "source": [
        "## Reading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "puKPHtnH0pIG"
      },
      "outputs": [],
      "source": [
        "s1raw     = pd.read_csv(\"../data/s1.csv\")\n",
        "s1_2raw   = pd.read_csv(\"../data/s1_2u.csv\")\n",
        "df2017raw = pd.read_csv(\"../data/df2017.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZd_8wpNFIYx"
      },
      "source": [
        "## Droping cols and OneHotEncoding aka set dummy variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "3jO-8xydbpbp"
      },
      "outputs": [],
      "source": [
        "def preprocess(csv_file):\n",
        "  csv_file = csv_file.drop([\n",
        "    'Unnamed: 0',\n",
        "    'month', \n",
        "    'flat_type', \n",
        "    'address',\n",
        "    'lease_commence_date'\n",
        "    # these 5, try removing to see the effects on data\n",
        "    ,'year'\n",
        "    ,'years'\n",
        "    ,'quarter'\n",
        "    #,'Lat'\n",
        "    #,'Lon'\n",
        "    ],axis = 1)\n",
        "\n",
        "  onehot = OneHotEncoder()\n",
        "\n",
        "  town_df = pd.DataFrame(onehot.fit_transform(csv_file[['town']]).toarray())\n",
        "  town_df.columns = onehot.get_feature_names_out(['town'])\n",
        "\n",
        "  flat_model_df = pd.DataFrame(onehot.fit_transform(csv_file[['flat_model']]).toarray())\n",
        "  flat_model_df.columns = onehot.get_feature_names_out(['flat_model'])\n",
        "\n",
        "  csv_file = csv_file.join([town_df, flat_model_df])\n",
        "  csv_file = csv_file.drop(['town','flat_model'], axis = 1)\n",
        "\n",
        "  return csv_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mfVnM0fIOIUf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['floor_area_sqm', 'resale_price', 'remaining_lease', 'index', 'Lat', 'Lon', 'dist_presch', 'dist_gym', 'dist_park', 'dist_pharm', 'dist_mrt', 'dist_hawker', 'storey_index', 'k_fold', 'town_BUKIT BATOK', 'town_BUKIT MERAH', 'town_CLEMENTI', 'town_JURONG WEST', 'town_SENGKANG', 'town_TAMPINES', 'town_TOA PAYOH', 'town_WOODLANDS', 'flat_model_2-room', 'flat_model_Apartment', 'flat_model_DBSS', 'flat_model_Improved', 'flat_model_Maisonette', 'flat_model_Model A', 'flat_model_Model A-Maisonette', 'flat_model_Model A2', 'flat_model_Multi Generation', 'flat_model_New Generation', 'flat_model_Premium Apartment', 'flat_model_Premium Maisonette', 'flat_model_Simplified', 'flat_model_Standard', 'flat_model_Adjoined flat']\n"
          ]
        }
      ],
      "source": [
        "s1_2 = preprocess(s1_2raw)\n",
        "\n",
        "add_flat = np.zeros(1091)\n",
        "## since flat_model_Adjoined flat is not in the data \n",
        "s1_2[\"flat_model_Adjoined flat\"] = add_flat\n",
        "cols = list(s1_2.columns.values)\n",
        "## reorder back to the original col order\n",
        "s1_2 = s1_2[cols]\n",
        "\n",
        "df2017 = preprocess(df2017raw)\n",
        "\n",
        "savefile = open(\"savefile.txt\", \"w\")\n",
        "\n",
        "print(cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejj4tNAdFZ6y"
      },
      "source": [
        "## Spliting data to training and validation set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test set S1.2.2\n",
        "s1_2 = s1_2.loc[s1_2['k_fold'] == 2]\n",
        "s1_2 = s1_2.drop(['k_fold'],axis = 1)\n",
        "\n",
        "# \"Classes\" / actual values\n",
        "y_test = s1_2['resale_price'].tolist()\n",
        "\n",
        "# Values to test on\n",
        "s1_2 = s1_2.drop(['resale_price'], axis=1)\n",
        "x_test = s1_2.to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "f20M4R0bVUsj"
      },
      "outputs": [],
      "source": [
        "def k_fold(dataset, k: int):\n",
        "  test_num_of_rows = s1_2raw[s1_2raw[\"k_fold\"] == 1].count()[\"k_fold\"]\n",
        "  # Hyper params\n",
        "  max_feat = \"auto\"\n",
        "  min_sam_split = 2\n",
        "  min_sam_leaf = 1\n",
        "  min_weight = 0\n",
        "  crit = \"squared_error\"\n",
        "  #for max_feat in ['auto', 'sqrt', 'log2']:\n",
        "  #for min_sam_split in range(2, 110, 10):\n",
        "  #for min_sam_leaf in range(1, 110, 10):\n",
        "  #for min_weight in [i * 0.1 for i in range(0, 6)]:\n",
        "  #for crit in ['squared_error', 'poisson', 'absolute_error']:\n",
        "  p_diff_test_saved = 1\n",
        "  p_diff_valid_saved = 1\n",
        "\n",
        "  print(f'starting...', end = \"\")\n",
        "\n",
        "  # load from saved model.\n",
        "  # Uncomment EITHER this or the one below (MODEL)\n",
        "  model = joblib.load(\"savedModel.joblib\")\n",
        "\n",
        "  for fold_num in range(1, k + 1):\n",
        "    print(f'{fold_num}', end = \"\")\n",
        "\n",
        "    # Validation set\n",
        "    validation    = dataset.loc[dataset['k_fold'] == fold_num]\n",
        "    validation    = validation.drop(['k_fold'], axis = 1)\n",
        "    y_validation  = validation['resale_price'].tolist()\n",
        "    validation    = validation.drop(['resale_price'], axis = 1)\n",
        "    x_validation  = validation.to_numpy()\n",
        "\n",
        "    # Training set\n",
        "    train   = dataset.loc[dataset['k_fold'] != fold_num]\n",
        "    train   = train.drop(['k_fold'], axis = 1)\n",
        "    y_train = train['resale_price'].tolist()\n",
        "    train   = train.drop(['resale_price'], axis = 1)\n",
        "    x_train = train.to_numpy()\n",
        "\n",
        "    # Random Forest\n",
        "    # Uncomment EITHER this or the one above (MODEL)\n",
        "    # model = RandomForestRegressor(\n",
        "    #   n_estimators = 90, \n",
        "    #   max_depth = 18, \n",
        "    #   random_state = 0, \n",
        "    #   n_jobs = -1,\n",
        "    #   criterion = crit,\n",
        "    #   max_features = max_feat,\n",
        "    #   min_samples_split = min_sam_split,\n",
        "    #   min_samples_leaf = min_sam_leaf,\n",
        "    #   min_weight_fraction_leaf = min_weight      \n",
        "    #   )\n",
        "    # model.fit(x_train, y_train)\n",
        "    \n",
        "    y_test_pred = model.predict(x_test)\n",
        "    y_validation_pred = model.predict(x_validation)\n",
        "\n",
        "    # avg % diff in each fold\n",
        "    num_of_rows = df2017raw[df2017raw[\"k_fold\"] == fold_num].count()[\"k_fold\"]\n",
        "    p_diff_valid = sum(abs(y_validation - y_validation_pred) / y_validation) / num_of_rows\n",
        "    p_diff_test = sum(abs(y_test - y_test_pred) / y_test) / test_num_of_rows\n",
        "\n",
        "    if (p_diff_test < p_diff_test_saved):\n",
        "      p_diff_test_saved = p_diff_test\n",
        "      p_diff_valid_saved = p_diff_valid\n",
        "      # to save:\n",
        "      #joblib.dump(model, \"savedModel4.joblib\", compress=3)\n",
        "      # to load:\n",
        "      # model = joblib.load(\"savedModel.joblib\")\n",
        "    \n",
        "    savefile.write(f'{fold_num}, {p_diff_valid}, {p_diff_test}\\n')\n",
        "    savefile.flush()\n",
        "    print(f', {p_diff_valid}, {p_diff_test}')\n",
        "\n",
        "  print(\"\\n\", end = \"\")\n",
        "  print(f'Best - valid: {p_diff_valid_saved}, test: {p_diff_test_saved}')\n",
        "  #savedModel  - valid: 0.03970219427728985, test: 0.0640816996101494\n",
        "  #savedModel2 - valid: 0.03970219427728984, test: 0.06408169961014941\n",
        "  #savedmodel3 - valid: 0.039702194277289854, test: 0.06408169961014941"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting...1, 0.021959855967716366, 0.0640816996101494\n",
            "2, 0.021650838792550517, 0.06408169961014938\n",
            "3, 0.021220784676266046, 0.0640816996101494\n",
            "4, 0.021142484170544307, 0.0640816996101494\n",
            "5, 0.022021697685312615, 0.0640816996101494\n",
            "6, 0.021360590694391262, 0.06408169961014941\n",
            "7, 0.021394681034410157, 0.06408169961014938\n",
            "8, 0.039702194277289854, 0.0640816996101494\n",
            "9, 0.021549174093342904, 0.0640816996101494\n",
            "10, 0.02210983643009377, 0.0640816996101494\n",
            "\n",
            "Best - valid: 0.021650838792550517, test: 0.06408169961014938\n"
          ]
        }
      ],
      "source": [
        "k_fold(df2017, 10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of hdb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
